# WhiteBit â€“ Smart Mixed-Precision Inference with Reinforcement Learning

## ğŸš€ Project Overview

**WhiteBit** is a research-driven hackathon project that explores how **reinforcement learning** can be used to optimize the precision used in **neural network inference** â€” dynamically deciding when to use **FP8** or **FP16** to maximize **efficiency** without sacrificing **accuracy**.

### ğŸ§  Motivation

Modern neural networks can run faster and more energy-efficiently when using lower-precision operations like FP8. However, some layers are **more sensitive** than others, and uniform precision can hurt accuracy. WhiteBit uses **RL to learn which layers or operations** can be safely run in FP8, and which require higher precision.

The result: an **adaptive inference strategy** that finds the best trade-off between **speed** and **accuracy** â€” learned automatically.

---

## ğŸ” What WhiteBit Does

- Builds a **small, real-world-feeling neural net** for classification (MNIST/FashionMNIST)
- Measures **layer sensitivity** using condition numbers or loss gradients
- Lets an **RL agent decide** precision per layer (FP8 or FP16)
- Visualizes the learned precision policy and its effect on:
  - Model **accuracy**
  - Inference **compute cost**
- Provides a teaching mode to **learn RL from first principles** with visual examples

---

## ğŸ¯ Goals

| Goal                          | Status     |
|-------------------------------|------------|
| âœ… Optimize precision dynamically with RL  | In progress |
| âœ… Visualize layer-wise precision policy   | In progress |
| âœ… Plot accuracy vs. cost trade-off        | In progress |
| ğŸ§ª Add RL teaching mode via Streamlit + chatbot | Planned     |
| ğŸ§  Integrate Venice AI for interactive tuning | Planned     |

---

## ğŸ—ºï¸ Architecture

whitebit/ â”œâ”€â”€ core/ # Core RL and model logic â”‚ â”œâ”€â”€ whitebit_model.py â”‚ â””â”€â”€ rl_agent.py â”‚ â”œâ”€â”€ envs/ # Gym-compatible environments â”‚ â””â”€â”€ inference_env.py â”‚ â”œâ”€â”€ visuals/ # Visualizations and metrics â”‚ â””â”€â”€ model_map_plot.py â”‚ â”œâ”€â”€ streamlit_app/ # UI (teaching/demo mode) â”œâ”€â”€ docker/ # Docker deployment â””â”€â”€ README_Project_Overview.md

---

## ğŸ’¡ Educational Twist

WhiteBit also includes a **teaching layer**: an interactive interface that helps learners understand RL concepts like:
- Policy, value function, TD(Î»)
- Exploration-exploitation trade-offs
- Design choices for state/action/reward spaces

All backed by live visualizations and chatbot interaction via **Venice AI**.

---

## ğŸ“ˆ Optimization Trade-Off

We optimize for the **best position on the Pareto frontier**:

markdown
Copy
Edit
    â–²
Accuracy â”‚ â†â†â† Ideal â”‚ â”‚ â— FP16 only â”‚ â— WhiteBit (RL-optimized) â”‚ â— FP8 only â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ Compute Cost

yaml
Copy
Edit

---

## ğŸ§ª Try It Out

Coming soon:
- `toy_mixed_precision.py`: minimal demo with condition-based precision switching
- `train_whitebit.py`: RL loop to learn optimal precision decisions
- `streamlit_app/`: visualize model precision, decisions, and accuracy in real-time

---

## ğŸ™Œ Authors

- Gordon Koehn â€“ Streamlit, Docker, Venice AI integration
- Jonas Petersen â€“ RL research, architecture